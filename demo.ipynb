{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data and AI Democratization through PromptToQueryResult Function\n",
    "\n",
    "In the context of data and AI democratization, `PromptToQueryResult` could be a function that translates natural language prompts into database queries. This could be part of a larger system that allows non-technical users to interact with databases using natural language, which would democratize access to data and AI.\n",
    "\n",
    "## Business Value and Domain Problem Solutions\n",
    "\n",
    "### Business Value:\n",
    "\n",
    "- **Increased Efficiency:** Non-technical users can retrieve data without needing to learn SQL or other query languages, or without needing to wait for technical staff to retrieve the data for them.\n",
    "- **Reduced Costs:** Less time and resources are spent on training staff to use complex database systems, and less time is spent on data retrieval tasks by technical staff.\n",
    "- **Improved Decision Making:** With easier access to data, decision-making can be data-driven and timely, leading to better business outcomes.\n",
    "\n",
    "### Domain Problem Solved:\n",
    "\n",
    "- **Data Accessibility:** One of the challenges in data democratization is making data accessible to non-technical users. `PromptToQueryResult` could help solve this problem by providing a natural language interface to databases.\n",
    "- **AI Democratization:** By using AI to translate natural language prompts into database queries, `PromptToQueryResult` could also contribute to AI democratization. It could be part of a system that allows users to leverage the power of AI without needing to understand the technical details.\n",
    "\n",
    "## Implementation Details\n",
    "\n",
    "The selected code is written in Python and it's part of a larger program that uses a plugin-based architecture. The code is using a kernel object to manage plugins and their functions.\n",
    "\n",
    "- **Variable Definitions:** First, two variables are defined: `plugins_directory` and `file_path`. The `plugins_directory` variable is set to the string `\"plugins\"`, which is presumably the directory where the plugins are stored. The `file_path` variable is set to `\"data_schema.txt\"`, which is likely a file that contains a data schema.\n",
    "\n",
    "- **Reading Data Schema:** The `read_data_schema_from_file` function is then called with `file_path` as an argument. This function reads the data schema from the specified file and returns it as a string. The returned data schema is stored in the `data_schema` variable.\n",
    "\n",
    "- **Conditional Plugin Import:** Next, there's an if-statement that checks the `prompt_rephrase` variable. If `prompt_rephrase` is true, the code imports a plugin named `\"PromptPlugin\"` from the plugins directory using the `import_plugin_from_prompt_directory` method of the kernel object. This method returns a dictionary-like object of functions provided by the plugin. The `\"PromptRephraser\"` function from the `\"PromptPlugin\"` plugin is then stored in the `rephraserFunction` variable.\n",
    "\n",
    "- **Function Invocation:** The `rephraserFunction` is then invoked asynchronously using the `invoke` method of the kernel object. The `invoke` method is called with two arguments: the function to be invoked and a `KernelArguments` object that contains the data schema and a query. The result of the function invocation is stored in the `rephrased_prompt` variable.\n",
    "\n",
    "- **Importing Another Plugin:** Finally, the code imports another plugin named `\"DataPlugin\"` from the plugins directory and stores the `\"DatabaseDescriptor\"` function from this plugin in the `descriptorFunction` variable. This function can presumably be used later in the code to describe a database based on the data schema.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import PromptToQueryResult\n",
    "from services import Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await PromptToQueryResult(prompt_rephrase=True, debug=True ,selected_service=Service.ClaudeAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await PromptToQueryResult(prompt_rephrase=True, debug=True ,selected_service=Service.AzureOpenAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await PromptToQueryResult(prompt_rephrase=True, debug=True ,selected_service=Service.HuggingFace, model_name=\"Llama318BInstruct\", model_mode=\"chat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await PromptToQueryResult(prompt_rephrase=True, debug=True ,selected_service=Service.HuggingFace, model_name=\"mistralaiMixtral8xbInstruct01\", model_mode=\"chat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await PromptToQueryResult(prompt_rephrase=True, debug=True ,selected_service=Service.Gemini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import GenerateQuestions\n",
    "from main import ReadQuestionsAndGenerateAnswers\n",
    "from services import Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await GenerateQuestions(selected_service=Service.ClaudeAI, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await ReadQuestionsAndGenerateAnswers(filename=\"questions/2024-12-27.txt\", selected_service=Service.ClaudeAI, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await ReadQuestionsAndGenerateAnswers(filename=\"questions/2024-12-27.txt\", selected_service=Service.AzureOpenAI, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await ReadQuestionsAndGenerateAnswers(filename=\"questions/2024-12-27.txt\", selected_service=Service.Gemini, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await ReadQuestionsAndGenerateAnswers(filename=\"questions/2024-12-27.txt\", selected_service=Service.DeepSeek, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await GenerateQuestions(selected_service=Service.AzureOpenAI, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await ReadQuestionsAndGenerateAnswers(filename=\"questions/2025-01-03.txt\", selected_service=Service.ClaudeAI, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await ReadQuestionsAndGenerateAnswers(filename=\"questions/2025-01-03.txt\", selected_service=Service.AzureOpenAI, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await ReadQuestionsAndGenerateAnswers(filename=\"questions/2025-01-03.txt\", selected_service=Service.Gemini, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await GenerateQuestions(selected_service=Service.Gemini, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await ReadQuestionsAndGenerateAnswers(filename=\"questions/2025-01-04.txt\", selected_service=Service.ClaudeAI, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await ReadQuestionsAndGenerateAnswers(filename=\"questions/2025-01-04.txt\", selected_service=Service.AzureOpenAI, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await ReadQuestionsAndGenerateAnswers(filename=\"questions/2025-01-04.txt\", selected_service=Service.Gemini, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await ReadQuestionsAndGenerateAnswers(filename=\"questions/2025-04-07.txt\", selected_service=Service.ClaudeAI, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await ReadQuestionsAndGenerateAnswers(filename=\"questions/2025-04-07.txt\", selected_service=Service.AzureOpenAI, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await ReadQuestionsAndGenerateAnswers(filename=\"questions/2025-04-07.txt\", selected_service=Service.DeepSeek, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await ReadQuestionsAndGenerateAnswers(filename=\"questions/2025-04-07.txt\", selected_service=Service.Gemini, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await ReadQuestionsAndGenerateAnswers(filename=\"questions/2025-04-07.txt\", selected_service=Service.Llama, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import process_scores\n",
    "from services import Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await process_scores(\"2025-04-07\", \"scores/2025-04-07.xlsx\", Service.AzureOpenAI)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
